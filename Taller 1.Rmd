---
title: '**Taller 1 Multivariado**'
author: "**Juan Jose Rodriguez Cubillos** | **Paula Sofia Torres Rodriguez** \n\n
  **Mauricio Rodriguez Cordoba** \n\n **Mariana D√≠az Puentes**"
date: "**2024-08-10**"
output:
  pdf_document:
   latex_engine: lualatex
header-includes:
 - \usepackage{fontspec}
 - \usepackage{unicode-math}
geometry: left=2cm, right=2cm, top=2cm, bottom=2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("tidyverse")
#install.packages("dplyr")
#install.packages("MASS")
#install.packages("knitr")
#install.packages("kableExtra")
#install.packages("car")
require(kableExtra)
require(tidyverse)
require(MASS)
require(MVN)
require(mvShapiroTest)
require(dplyr)
require(knitr)
require(ggplot2)
require(corrplot)
require(psych)
require(car)
require(tinytex)
require(readr)
require(MVA)
```


## Introducci√≥n

<div style="text-align: justify;">

El objetivo del informe es realizar un an√°lisis detallado para explorar la normalidad multivariada en un conjunto de datos. A lo largo del informe, se abordar√°n diferentes etapas del an√°lisis, la obtenci√≥n de estad√≠sticas descriptivas, la visualizaci√≥n de correlaciones, y la aplicaci√≥n de pruebas informales de normalidad multivariada. Este an√°lisis permitir√° determinar si los datos cumplen con las suposiciones de normalidad multivariada.

<div style="text-align: justify;">
# Punto 1

En el archivo anexo1.csv contiene los datos de una muestra de vectores aleatorios de 3 componentes, X1,X2,...,X40.

```{r Carga del archivo, message=FALSE, warning=FALSE, include=FALSE}
datos <- read_delim("anexo1.csv", delim = ";", 
    escape_double = FALSE, trim_ws = TRUE)

datos <- as.data.frame(lapply(datos, function(x) {
  if(is.character(x)) {
    as.numeric(gsub(",", ".", x))
  } else {
    x
  }
}))
```


## a. Evalue la normalidad multivariada de la muestra dada.

### Analisis exploratorio de los datos

### Verificacion de datos faltantes

<div style="text-align: justify;">
Examinar los datos faltantes, con el fin de lograr asegurar que los resultados no est√©n sesgados ni incorrectos.

```{r Verificacion datos nulos, warning=FALSE}

# Verificamos cu√°ntos valores faltantes hay por columna
colSums(is.na(datos))
```

### Estad√≠sticas descriptivas

<div style="text-align: justify;">
Para determinar si este conjunto de datos se considera normal multivariado, se realizar√° una investigaci√≥n inicial de forma descriptiva de cada variable. Se observar√° si presentan alg√∫n comportamiento normal univariado y se analizar√°n las posibles correlaciones entre ellas.

### Grafico de dispersion de los datos

<div style="text-align: justify;">
El gr√°fico de dispersi√≥n muestra la relaci√≥n entre dos variables cuantitativas. Observando la disposici√≥n de los puntos, podemos identificar si existe una tendencia lineal o curvil√≠nea entre las variables, o si no hay relaci√≥n aparente. 

### Scatter Plot
```{r Dispersion de datos, echo=FALSE, fig.align='center',fig.width=5, fig.height=4}

par(mfrow = c(1, 2))
# Graficamos la matriz de gr√°ficos de dispersi√≥n b√°sica
pairs(datos)
par(mfrow = c(1, 1))
```

<div style="text-align: justify;">

En la matriz de gr√°ficos de dispersi√≥n mostrada, se visualizan las relaciones bivariadas entre las tres variables X1, X2 y X3. Cada gr√°fico individual representa un par de variables, donde los puntos muestran c√≥mo una variable se relaciona con la otra. 

Se observa una tendencia positiva en las relaciones entre las variables, indicando que a medida que una de las variables aumenta, la otra tambi√©n tiende a aumentar. Esta correlaci√≥n positiva es evidente en todos los pares de variables: X1 vs X2, X1 vs X3, y X2 vs X3. La alineaci√≥n de los puntos en una direcci√≥n ascendente sugiere una relaci√≥n lineal fuerte entre las variables. 


## Prueba de normalidad multivariada informal

### Gr√°fico de dispersi√≥n con elipses de confianza


```{r Prueba de normalidad multivariada informal, echo=FALSE, fig.align='center',fig.height=3}

par(mfrow = c(1,3))

# x1 x2
x1x2 <- data.frame(datos$X1, datos$X2)
y1 <- as.matrix.data.frame(x1x2)
bvbox(y1, method = "robust",
      xlab = expression(x[1]),
      ylab = expression(x[2]))

# x1 x3
x1x3 <- data.frame(datos$X1, datos$X3)
y2 <- as.matrix.data.frame(x1x3)
bvbox(y2, method = "robust",
      xlab = expression(x[1]),
      ylab = expression(x[3]))

# x2 x3
x2x3 <- data.frame(datos$X2, datos$X3)
y3 <- as.matrix.data.frame(x2x3)
bvbox(y3, method = "robust",
      xlab = expression(x[2]),
      ylab = expression(x[3]))

# Restablecemos la disposici√≥n de gr√°ficos a la configuraci√≥n predeterminada
par(mfrow = c(1, 1))

```
<div style="text-align: justify;">
En los tres gr√°ficos, las elipses de confianza abarcan la mayor√≠a de los puntos, lo que indica que las relaciones bivariadas entre las variables (X1 vs X2, X1 vs X3, y X2 vs X3) son consistentes con la suposici√≥n de normalidad multivariada. Las elipses permiten identificar la concentraci√≥n de los datos y sugiere que no hay desviaciones significativas de la normalidad en los pares de variables analizados. Esto es un indicio que existe una normal multivariada en esta muestra.

### QQplot normal multivariada

<div style="text-align: justify;">
En el gr√°fico Q-Q multivariado, comparamos las distancias de Mahalanobis calculadas a partir de los datos observados con los cuantiles te√≥ricos de una distribuci√≥n chi-cuadrado. Matem√°ticamente, la distancia de Mahalanobis para las observaciones:

$$
X: d_i^2 = (\mathbf{X} - \bar{\mathbf{X}})^\top \mathbf{\Sigma}^{-1} (\mathbf{X} - \bar{\mathbf{X}})
$$
<div style="text-align: justify;">
El objetivo es ver si las distancias de Mahalanobis siguen la distribuci√≥n esperada bajo la normalidad multivariada. Si los datos son multivariadamente normales, las distancias deber√≠an alinearse a lo largo de una l√≠nea recta en el gr√°fico Q-Q.
```{r Prueba de normalidad multi, message=FALSE, warning=FALSE,fig.align='center',fig.width=5, fig.height=4}

X <- as.matrix(datos)
Xbarra<-colMeans(X)
S<-cov(X)
dm <- mahalanobis(X,Xbarra,S)
cuantiles <- qchisq(ppoints(length(X)),df=4)
# Asignamos n√∫mero de observaciones y dimensi√≥n
n <- length(dm)
p <- 3

# Calculamos los cuantiles te√≥ricos de la distribuci√≥n chi-cuadrado con p grados de libertad
teoricos <- qchisq(ppoints(n), df = p)

# Primero, generamos el gr√°fico
qqplot(teoricos, dm, main="QQ Plot de las Distancias de Mahalanobis", 
       xlab="Cuantiles Teoricos Chi cuadrado", 
       ylab="Distancias de Mahalanobis Observadas")

# Luego, agregamos la l√≠nea diagonal
abline(0, 1, col="red", lwd=2)
```


<div style="text-align: justify;">

En el gr√°fico, se observa que los puntos se alinean bastante bien con la l√≠nea roja en las partes centrales, lo que sugiere que los datos en ese rango siguen aproximadamente una distribuci√≥n normal multivariada.
Sin embargo, en los extremos, algunos puntos comienzan a desviarse de la l√≠nea. Estos puntos indican que las distancias de Mahalanobis en los extremos no siguen tan bien la distribuci√≥n chi-cuadrado esperada. Este comportamiento podr√≠a ser una se√±al de la presencia de valores at√≠picos o de una distribuci√≥n diferente a la normal en esos extremos.

## Prueba de normalidad multivariada formal

<div style="text-align: justify;">
A diferencia de las pruebas informales, como los gr√°ficos Q-Q multivariados, las pruebas formales proporcionan un criterio estad√≠stico objetivo para determinar si se puede aceptar o rechazar la hip√≥tesis de que los datos son multivariadamente normales.


Suponga que la muestra fue extra√≠da de una poblaci√≥n:

\[
\text{Pob} \quad X_i = \begin{pmatrix} 
X_1 \\
X_2 \\
X_3 
\end{pmatrix}
\]

\text{El inter√©s es probar las hip√≥tesis:}

\[
\begin{aligned}
\text{H}_0 &: \mathbf{X} \sim N_3 \left( 
\begin{pmatrix} 
\mu_1 \\
\mu_2 \\
\mu_3 
\end{pmatrix}, 
\begin{pmatrix} 
\sigma_1^2 & \sigma_{12} & \sigma_{13} \\
\sigma_{21} & \sigma_2^2 & \sigma_{23} \\
\sigma_{31} & \sigma_{32} & \sigma_3^2 
\end{pmatrix} 
\right) \\[1em]  % Espacio entre hip√≥tesis
\text{H}_1 &: \mathbf{X}_{3 \times 1} \not\sim N_3 \left( 
\begin{pmatrix} 
\mu_1 \\
\mu_2 \\
\mu_3 
\end{pmatrix}, 
\begin{pmatrix} 
\sigma_1^2 & \sigma_{12} & \sigma_{13} \\
\sigma_{21} & \sigma_2^2 & \sigma_{23} \\
\sigma_{31} & \sigma_{32} & \sigma_3^2 
\end{pmatrix} 
\right)
\end{aligned}
\]

Para resolver esta prueba de hip√≥tesis, se usar√°n distintos m√©todos con el fin de comprobar el supuesto de normalidad multivariada, adem√°s de compararlos y observar si existe una diferencia entre ellos.

### Prueba De Shapiro 
```{r Prueba formal, message=FALSE, warning=FALSE}

# ----- Prueba de Shapiro ----- #
require(mvShapiroTest)
mvShapiro.Test(X)
# ----- Otras Pruebas ----- #
mvn(X, mvnTest="mardia") # test de Mardia
mvn(X, mvnTest="hz") # test de Henze-Zirkler
mvn(X, mvnTest="royston") # test de Royston
mvn(X, mvnTest="dh") # test de Doornik-Hansen
```
Al observar los test, se logra identificar que no se obtuvo suficiente evidencia para rechazar H0, por ende es una muestra con comportamiento normal multivariado, ensta muestra de 3 variables y 40 unidades de investigacion, las pruebas demuestran suficiente potencia para ello.

Sin embargo, seg√∫n Porras Cerron (2016), cuando se eval√∫a la potencia de las pruebas de normalidad multivariada, los resultados indican que no hay diferencias significativas entre las pruebas analizadas. Sin embargo, se observa que al aumentar el n√∫mero de investigaciones o variables en el estudio, la potencia de algunas pruebas, como la de Mardia, tiende a disminuir ligeramente. Por otro lado, en pruebas como la de Royston, la potencia puede aumentar a medida que se incrementa el tama√±o de la muestra o el n√∫mero de variables. Esto sugiere que la elecci√≥n de la prueba m√°s adecuada puede depender de la estructura y tama√±o de los datos utilizados en la investigaci√≥n.



## b. Si el vector de medias poblacionales es $\mu = [0.1, -0.2, 0.05]^t$ y $S$ es la matriz de varianzas-covarianzas muestrales. ¬øCu√°l es la distribuci√≥n aproximada de $40 \left(\overline{X} - [0.1, -0.2, 0.05]^t\right)^t S^{-1} \left(\overline{X} - [0.1, -0.2, 0.05]^t\right)$?

Para resolver este problema, primero se debe partir de la formula general de las distancias  de Mahalanobis muestrales para cualquier vector p variado $X$: $d_i^2 = (\mathbf{X} - \bar{\mathbf{X}})^\top \mathbf{\Sigma}^{-1} (\mathbf{X} - \bar{\mathbf{X}})$, donde $\mathbf{X}$ es el vector de datos, $\bar{\mathbf{X}}$ es el vector de medias muestrales y $\mathbf{\Sigma}$ es la matriz de varianzas-covarianzas poblacionales. 

Si consideramos la distribuci√≥n del vector de medias muestrales $\overline{X}$, se tiene que $\overline{X} \sim N_p(\mu, \frac{\Sigma}{n})$. Por lo tanto, la distribuci√≥n de la distancia de Mahalanobis muestral es $d_i^2 = (\overline{X} - \mu)^\top \left(\frac{\Sigma}{n}\right)^{-1} (\overline{X} - \mu) \sim \chi^2_p$, y considerando el teorema de limite central y que el vector de medias muestrales es un estimador insesgado de $\mu$, se tiene que la varianza muestral es $S$ tiende a la poblacional $\Sigma$. Teniendo en cuenta esto, el vector de distancias de Mahalanobis muestrales para la media se podria escribir como $d_i^2 = (\overline{X} - \mu)^\top (\frac{S}{n})^{-1} (\overline{X} - \mu)$. Si se reescribe esta formula modificando el exponente de n la formula queda de la siguiente manera: $d_i^2 = n(\overline{X} - \mu)^\top S^{-1} (\overline{X} - \mu)$, la cual corresponde a la formula que buscamos estudiar y uqe podemos concluir que corresponde a la distancia de Mahalanobis muestral para el vector de medias poblacionales. Por lo tanto, la distribuci√≥n aproximada de $40 \left(\overline{X} - [0.1, -0.2, 0.05]^t\right)^t S^{-1} \left(\overline{X} - [0.1, -0.2, 0.05]^t\right)$ es $\chi^2_3$.


## c. Usando la distancia cuadrada generalizada establezca si existen valores at√≠picos.


```{r Valores Atipicos, echo=TRUE, fig.align='center'}
par(mfrow = c(1,1.5))

X<-as.matrix(datos)
Xbarra<-colMeans(X)
S<-cov(X)
dm<-mahalanobis(X,Xbarra,S)
cuantiles<-qchisq(ppoints(length(X)),df=4)
Out<-mvn(datos, mvnTest = "mardia",
         multivariateOutlierMethod ="adj") 




```

<div style="text-align: justify;">
Se logra identificar 3 datos at√≠picos (21,29 y 35), de los cuales se encuentran a la derecha del cuartil de la chi cuadrado ajustada (9.348), indicada por la l√≠nea azul. Esto significa que la distancia de Mahalanobis de estas unidades de investigaci√≥n son inusualmente altas.  
Al observar estos resultados, se puede deducir que la cantidad de valores at√≠picos en datos multivariados aumenta con el n√∫mero de variables, ya que la probabilidad de que una observaci√≥n se aleje significativamente de la media en alguna dimensi√≥n aumenta. Sin embargo, esta relaci√≥n no es estrictamente proporcional depender√° de factores como la correlaci√≥n y estructura de los datos. 



### Referencia
Porras Cerron, J. C. (2016). Comparaci√≥n de pruebas de normalidad multivariada. Anales Cient√≠ficos, 77(2), 141-146. https://doi.org/10.21704/ac.v77i2.483

# Punto 2
## Realizamos la carga de datos

**MultBiplotR** provee a traves de los datos *Protein* la informaci√≥n de datos nutricionales para habitantes de 25 paises de europa en la decadada de los 70s. Las variables presentes son: 

‚Ä¢ **Comunist:** Presencia del comunismo en el pa√≠s 

‚Ä¢ **Region:** Nombre de la regi√≥n que se encuentra el pa√≠s

‚Ä¢ **RedMeat:** Consumo de prote√≠nas provenientes de carnes rojas.

‚Ä¢ **WhiteMeat:** Consumo de prote√≠nas provenientes de carnes blancas.

‚Ä¢ **Eggs:** Consumo de prote√≠nas del huevo.

‚Ä¢ **Milk:**Consumo de prote√≠nas de la leche.

‚Ä¢ **Fish:** Consumo de prote√≠nas provenientes del pescado.

‚Ä¢ **Cereals:** Consumo de prote√≠nas procedentes de cereales.

‚Ä¢ **Starch:** Consumo de prote√≠nas provenientes de carbohidratos.

‚Ä¢ **Nuts:** Consumo de prote√≠nas procedentes de cereales, frutos secos y semillas oleaginosas.

‚Ä¢ **FruitVeg:** Consumo de prote√≠nas procedentes de frutas y verduras.

Como se puede observar, nueve de las variables representan diferentes fuentes de prote√≠na. Asumimos que todas est√°n expresadas en **gramos por persona por d√≠a**. Aunque esto no es expl√≠cito en la documentaci√≥n, se consultaron trabajos como los del programa de inteligencia de negocios la [Universidad de Texas](https://github.com/jgscott/STA380/tree/master), donde se adopt√≥ la misma suposici√≥n.

Dado lo anterior, procedemos a instalar el paquete **MultBiplotR**, renombrando y convirtiendo a DataFrame el dataset *Protein*.
```{r , message = FALSE}
#install.packages("MultBiplotR")
require(MultBiplotR)

# Renombramos y convertimos a Data Frame
Data <- Protein  %>% as.data.frame()

# Hacemos unas modificaciones para mostrar el nombre del pa√≠s
Data$Country <- rownames(Data)
rownames(Data) <- NULL  
Data <- Data[, c("Country", colnames(Data)[-ncol(Data)])]

# Mostramos los datos
kable(Data) %>% kable_styling(font_size = 6, full_width = FALSE)
```


## a. Determine y analice el vector de medias y la matriz de covarianzas muestrales para las **diferentes regiones.**


### Vector De Medias

Dado que tenemos la muestra, \(\mathbf{X}_1, \mathbf{X}_2, \dots, \mathbf{X}_{25}\), nuestro objetivo es calcular y analizar el vector de medias \(\boldsymbol{\overline{\symbf{x}}} = \begin{pmatrix}\overline{x}_1 \\\overline{x}_2 \\\vdots \\\overline{x}_{9}\end{pmatrix}\), para ello calculamos las medias de cada una de las 9 variables n√∫mericas, exceptuando *Comunist* y *Region*.

```{r}
#Filtramos para quitar Region y Comunist
F_Data <-  Data[, !(colnames(Data) %in% c("Country", "Comunist", "Region"))]

# Calculamos y mostramos el vector de medias
kable(colMeans(F_Data), col.names = "$\\overline{X}$")
```

De acuerdo con los resultados, los cereales son, en promedio, la principal fuente de prote√≠na diaria por persona, seguidos por la leche. En contraste, los huevos y las nueces proporcionan la menor cantidad de prote√≠na. Las dem√°s fuentes contribuyen con entre 4 y 9 gramos de prote√≠na al d√≠a por persona.


### Matriz Covarianzas

Para nuestro otro objetivo que es la matriz de covarianzas $\symbf{\Sigma} = \begin{pmatrix}\sigma_{11} &\sigma_{12} & \sigma_{13} & \cdots & \sigma_{1,9} \\\sigma_{21} & \sigma_{22} & \sigma_{23} & \cdots & \sigma_{2,9} \\\sigma_{31} & \sigma_{32} & \sigma_{33} & \cdots & \sigma_{3,9} \\\vdots     & \vdots     & \vdots     & \ddots & \vdots \\\sigma_{9,1} & \sigma_{9,2} & \sigma_{9,3} & \cdots & \sigma_{9,9} \\\end{pmatrix}$ necesitamos excluir de nuevo a las variables *Comunist* y *Region*, y calcular la informaci√≥n que proporciona la matriz para las 9 variables.

```{r}
# Calculamos y mostramos el vector de medias
kable(cov(F_Data), digits = 3) %>%  kable_styling(font_size = 8, full_width = FALSE)
```
En la figura anterior se presenta la matriz de varianzas y covarianzas, donde en la diagonal se pueden identificar las varianzas de las variables correspondientes. Se observa que la variable 'Cereal' tiene una varianza aproximadamente de 120, lo que, en comparaci√≥n con otras variables, resulta considerablemente alta. De manera similar, la columna 'Milk', aunque no tan extrema con un valor de 50, tambi√©n muestra una varianza relativamente grande, seguida de 'Fish', 'Red Meat' y 'White Meat', con un valor al entre 11 y 12. Las dem√°s variables mantienen varianzas en un rango de 1 a 3.5.

En cuanto a las covarianzas, es importante recordar que esta matriz revela la direcci√≥n de la relaci√≥n entre las variables (positiva o negativa) sin indicar su magnitud absoluta. Se destacan relaciones negativas significativas entre 'Cereal' y 'Milk', as√≠ como entre 'Cereal' con 'Red Meat' y 'White Meat'. Por otro lado, las relaciones positivas m√°s notables se observan entre 'Milk' y 'Red Meat'.


## b. Calcule la media de las variables por regiones ¬øque puede decir al respecto?

Con el fin de calcular las medias por regi√≥n realizamos un filtro que permita agrupar los pa√≠ses por regiones, y luego procedemos a realizar el c√°lculo de la media de todas las variables, lo que resulta en la siguiente matriz:

```{r, warning=FALSE}
# Agrupamos los datos por regi√≥n
G_Data <- Data %>% group_by(Region)

# Realizamos el calculo de las medias a lo largo de las variables n√∫mericas
MediaxRegion <- G_Data %>% summarize(
    across(Red_Meat:Fruits_Vegetables, mean, na.rm = TRUE)
  )

#Mostramos las medias por region
kable(MediaxRegion, digits = 3, caption = "Vectores De Medias Por Regi√≥n") %>%
  kable_styling(font_size = 10, full_width = FALSE)
```
En la tabla se observa que, en la regi√≥n del norte, la prote√≠na m√°s consumida es la leche, mientras que en el centro y el sur predomina el cereal. Las nueces son en promedio las menos consumidas en el norte y el centro, mientras que, en el sur, los huevos registran el menor consumo. 

Poe otro lado, no se identifica un patr√≥n de consumo promedio similar para ninguna prote√≠na espec√≠fica entre las distintas regiones. Sin embargo, en la zona sur, el consumo promedio de carnes blancas y pescados es similar, al igual que el de nueces y frutas y vegetales. De manera similar ocurre en la regi√≥n central respecto a el consumo promedio de huevos y pescado.

## c. Intente construir grupos de paises usando representaciones pict√≥ricas (gr√°ficos de estrellas o caras de Chernoff).

Con el fin realizar los posibles grupos de pa√≠ses vamos a observar c√≥mo sale nuestro gr√°fico de estrellas ya que es un gr√°fico m√°s reconocible para mirar que pa√≠ses pueden ser agrupados mediante una puntuaci√≥n alta de las variables compartidas: 

```{r, fig.align='center', fig.height= 5, fig.width= 6}
# Hacemos la funci√≥n de escalado de Min-Max
min_max_norm <- function(x) {
  (x - min(x)) / (max(x) - min(x))}

# Escalamos las variables usando Min-Max 
F_Data_std <- F_Data %>% mutate(across(everything(), min_max_norm)) %>% as.data.frame()    

# A√±adimos la columna para indentificar los pa√≠ses
F_Data_std$Country <- Data$Country

# Creamos y mostramos el gr√°fico de estrellas con ajustes
stars(F_Data_std[, -10], labels = F_Data_std$Country,key.loc = c(15, 1.25), 
main = "Gr√°ficos de Estrellas para Pa√≠ses", draw.segments = TRUE,
col.segments = rainbow(ncol(F_Data_std) - 1), cex.main = 1.5, 
cex.lab = 2, lty = 1.5, ncol = 8)                   
```

### Analisis Grupos

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth, height=0.45\textheight]{SDN.png}
\caption{Grupo Con Alto Consumo de Huevos, Leche y Carnohidratos}
\end{figure}

En el primer grupo encontramos 3 pa√≠ses pertenecientes al norte de Europa, donde debido a las bajas temperaturas la siembra de varios cultivos es muy complicada as√≠ que su consumo de prote√≠na se evidencia en otros productos, relacionados al mundo de la ganader√≠a y prote√≠nas de origen animal, siendo la leche, los huevos y otros carbohidratos los principales, aunque tambi√©n destacan las carnes rojas, blancas y el pescado. 

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth, height=0.45\textheight]{GBU.png}
\caption{Grupo Con Alto Consumo de Huevos, Carne Blanca y Carnohidratos}
\end{figure}

El consumo de prote√≠na de este grupo de pa√≠ses del centro de Europa tambi√©n proviene principalmente de origen animal, sin embargo, a diferencia del primer grupo el consumo de pescado y leche disminuye bastante, pero se ve que hay un mayor consumo de carnes rojas y blancas (principalmente las blancas) aunque si se mantiene el alto consumo de huevos y carbohidratos. 

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth, height=0.45\textheight]{RBY.png}
\caption{Grupo Con Alto de Cereales y Frutos Secos}
\end{figure}

Este √∫ltimo grupo situado al este de Europa es el m√°s distinto de los 3 porque, excepto el pescado, el consumo de prote√≠nas animal disminuye mucho (el de carbohidratos tambi√©n disminuy√≥) y los frutos secos se alzan como una de las principales fuentes de prote√≠nas, junto con el pescado, para esta regi√≥n.  

## d. Utilice las herramientas de gr√°ficas m√°s adecuadas para verificar normalidad multivariada.

```{r, echo = FALSE, fig.height= 5,  fig.width=6, fig.align='center'}
Data_means<-colMeans(F_Data)
Data_Cov<-cov(F_Data)
dm<-mahalanobis(F_Data ,Data_means,Data_Cov)
cuantiles<-qchisq(ppoints(nrow(F_Data)),df=9)
qqplot(cuantiles,dm)
abline(0,1)
```

La gr√°fica sugiere que los datos transformados est√°n alineados en su mayor√≠a con una distribuci√≥n chi-cuadrado, lo que sugiere que podr√≠an provenir de una distribuci√≥n normal multivariada. No obstante, las desviaciones en los extremos podr√≠an indicar la presencia de valores at√≠picos, lo que justifica una investigaci√≥n m√°s detallada (como una prueba formal) para confirmar esta hip√≥tesis.

## e. Realice la prueba de Mardia para verificar las hip√≥tesis:
### H0 : Los datos provienen de una poblacion Normal Multivariada
### H1 : Los datos NO provienen de una poblacion Normal Multivariada

```{r, echo = FALSE, message = FALSE}
# Realizamos los test de normalidad multivariada y univariada
mvn_result <- mvn(F_Data, mvnTest = "mardia", univariateTest = "AD")

# Extraemos los valores que nos interesan para la normalidad multivariada
test_names_mv <- mvn_result$multivariateNormality$Test
p_values_mv <- as.numeric(as.character(mvn_result$multivariateNormality$`p value`))
results_mv <- mvn_result$multivariateNormality$Result

# Extraemos los valores que nos interesan para la normalidad univariada
test_names_uv <- mvn_result$univariateNormality$Test
variables_uv <- mvn_result$univariateNormality$Variable
p_values_uv <- as.numeric(as.character(mvn_result$univariateNormality$`p value`))
results_uv <- mvn_result$univariateNormality$Normality

# Construimos los data frames
results_mv_df <- data.frame(
  Test = test_names_mv,
  Variable = NA,  # A√±adimos la columna 'Variable' con NA para mantener la consistencia
  `p-value` = ifelse(is.na(p_values_mv), "NA", round(p_values_mv, 3)),
  Result = results_mv
)

results_uv_df <- data.frame(
  Test = test_names_uv,
  Variable = variables_uv,
  `p-value` = ifelse(is.na(p_values_uv), "NA", round(p_values_uv, 3)),
  Result = results_uv
)

# Renombramos la columna "Result" a "Normality" en ambas tablas para consistencia
colnames(results_mv_df)[4] <- "Result/Normality"
colnames(results_uv_df)[4] <- "Result/Normality"

# Combinamos los data frames para mostrarlos juntos
combined_results_df <- rbind(results_mv_df, results_uv_df)

# Mostramos los resultados en una tabla
kable(combined_results_df, col.names = c("Test", "Variable", "p-value", "Result/Normality")) %>%
  kable_styling(font_size = 12, full_width = FALSE)
```

Podemos observar que la prueba de Mardia no rechaza la hip√≥tesis nula (H0), lo que indica que los datos podr√≠an provenir de una poblaci√≥n normal multivariada, con un p-valor aproximado de 0.42 para la asimetr√≠a y 0.60 para la curtosis.

En las pruebas de normalidad univariadas, notamos que algunas variables no cumplen con el supuesto de normalidad. Espec√≠ficamente, las variables Cereal, Nuts, y Fruits_Vegetables presentan p-valores de 0.0101, 0.0155, y 0.0380, respectivamente, lo que sugiere que estas distribuciones se desv√≠an significativamente de la normalidad. No obstante, los p-valores no son extremadamente bajos, lo que podr√≠a explicar por qu√© la normalidad multivariada conjunta no fue rechazada.


## f. Verifique si hay outliers (multivariados) e identif√≠quelos.

```{r, echo = FALSE}
# Realizamos el an√°lisis
Out <- mvn(Data[, c(-1,-2,-3)], mvnTest = "mardia",
           multivariateOutlierMethod = "quan")

# Colocamos los outliers correspondientes con sus pa√≠ses
outlier_labels <- c("Poland", "Greece", "France", "Albania", "Denmark", "Romania", "Portugal", "Spain")
outlier_indices <- c(16, 10, 9, 1, 6, 18, 17, 19) 

# A√±adimos la leyenda
legend("bottomright", legend = paste(outlier_indices, outlier_labels, sep = " = "),
       col = "red", pch = 19, cex = 0.8)
```

Como podemos observar en el gr√°fico de distancia de mahalanobis robusta, vemos que son un total de 8 pa√≠ses que cuentan como outliers multivariados, entre ellos vemos un grupo conformado por 7 pa√≠ses que dentro de todo si se alejan en gran medida de la l√≠nea trazada de los outliers, entre ellos se encuentran pa√≠ses como **Polonia** que abre el grupo, **Albania** que es la mitad de este conjunto de pa√≠ses y **Portugal** que cierra este colectivo de puntos. 

Por √∫ltimo, no podemos dejar de ver a **Espa√±a** que es el pa√≠s m√°s alejado de todos, con una diferencia notable en cuanto a los no outliers, y m√°s a√∫n frente al agrupamiento de los otros 7 outliers, llegando a estar casi 150 puntos m√°s lejos en cuanto a la distancia de mahalanobis robusta. 

## g. Pruebe las hip√≥tesis

Dado el vecto de medias \(\boldsymbol{\mu_0} = \begin{bmatrix} 9, & 7, & 2, & 15, & 5, & 30, & 4, & 3, & 4 \end{bmatrix}^{\top}\), se tiene el inter√©s de comprabar los casos **Univariado** y **Multivariado** para saber si dicho vector es plausible para $\symbf{\mu}$.

### i. De forma **Univariada**

Se tienen las siguientes hipotesis para las 9 variables de los datos: 

*Variables *RedMeat*(${\mu_1}$), *WhiteMeat*(${\mu_2}$), *Eggs*(${\mu_3}$), *Milk*(${\mu_4}$) y *Fish*(${\mu_5}$)*

\[
\begin{array}{ccccc}
\begin{aligned}
\text{H}_0: \mu_1 &= 9 \\
\text{H}_1: \mu_1 &\neq 9 \\
\end{aligned}
&
\begin{aligned}
\text{H}_0: \mu_2 &= 7 \\
\text{H}_1: \mu_2 &\neq 7 \\
\end{aligned}
&
\begin{aligned}
\text{H}_0: \mu_3 &= 2 \\
\text{H}_1: \mu_3 &\neq 2 \\
\end{aligned}
&
\begin{aligned}
\text{H}_0: \mu_4 &= 15 \\
\text{H}_1: \mu_4 &\neq 15 \\
\end{aligned}
&
\begin{aligned}
\text{H}_0: \mu_5 &= 5 \\
\text{H}_1: \mu_5 &\neq 5 \\
\end{aligned}
\end{array}
\]

*Variables *Cereals*(${\mu_6}$), *Starch*(${\mu_7}$), *Nuts*(${\mu_8}$), *FruitVeg*(${\mu_9}$)*

\[
\begin{array}{cccc}
\begin{aligned}
\text{H}_0: \mu_6 &= 30 \\
\text{H}_1: \mu_6 &\neq 30 \\
\end{aligned}
&
\begin{aligned}
\text{H}_0: \mu_7 &= 4 \\
\text{H}_1: \mu_7 &\neq 4 \\
\end{aligned}
&
\begin{aligned}
\text{H}_0: \mu_8 &= 3 \\
\text{H}_1: \mu_8 &\neq 3 \\
\end{aligned}
&
\begin{aligned}
\text{H}_0: \mu_9 &= 4 \\
\text{H}_1: \mu_9 &\neq 4 \\
\end{aligned}
\end{array}
\]


```{r}
# Obtenemos los nombres de las columnas
variables <- colnames(F_Data) 

# Creamos los valores de mu para las prueba t
mu_value <- c(9, 7, 2, 15, 5, 30, 4, 3, 4)

# Creamos un DataFrame vac√≠o para almacenar los resultados
results <- data.frame(Variable = character(), P_Value = numeric(), stringsAsFactors = FALSE)

# Recorremos las columnas y realizamos el t.test para cada una
for (i in 1:length(variables)) {
  variable_name <- variables[i]
  test_result <- t.test(Data[[variable_name]], mu = mu_value[i], conf.level = 0.95)
  
  # A√±adimos los resultados al DataFrame
  results <- rbind(results, data.frame(Variable = variable_name, P_Value = test_result$p.value))
}

# Mostramos los resultados de los p-valores
kable(results)
```
Despu√©s de realizar pruebas t univariadas para cada variable, utilizando valores espec√≠ficos de ùúá como referencia para verificar las sospechas sobre la cantidad de gramos promedio de una determinada prote√≠na consumidos por persona al d√≠a en 25 pa√≠ses, se interpretaron los p-valores obtenidos bajo niveles de significancia de 0.01, 0.05 y 0.10.

A un nivel de significancia de 0.01, no se rechaza la hip√≥tesis nula para ninguna de las variables, lo que sugiere que las medias no difieren significativamente de los valores propuestos para ùúá. 

Al aplicar un nivel de significancia de 0.05, solo la variable "Eggs" mostr√≥ un p-valor menor a 0.05, lo que permite rechazar la hip√≥tesis nula e indica que su media difiere significativamente del valor ùúá. 

Al aumentar el nivel de significancia a 0.10, el resultado permanece constante, y "Eggs" sigue siendo la √∫nica variable para la cual se puede rechazar la hip√≥tesis nula. *Sin embargo, es importante se√±alar que podr√≠an existir otros valores de ùúá que tambi√©n sean consistentes con los datos, lo que introduce cierta incertidumbre en la interpretaci√≥n de los resultados por lo que debemos optar por realizar una prueba normal multivariada.*


### ii. De forma **Multivariada**

Dado que nuestro objetivo es contrastar si (en conjunto) el vector \(\mu_0\) dado es un valor plausible para \(\mu\) buscamos probar

$$
\begin{aligned}
\text{H}_0 &: \symbf{\mu} = \symbf{\mu_0} \\
\text{H}_1 &: \symbf{\mu} \neq \symbf{\mu_0}
\end{aligned}
$$
Usaremos la **Estad√≠stica de $T^2$ de Hoteling** que es una generalizaci√≥n de la prueba t univariada.

Obtuvimos a partir de la prueba el siguiente resultado:

```{r, fig.align='center', echo = FALSE }
T2_Hot<-function(mu0,alpha,n){
Data_means<-colMeans(F_Data)
Data_Cov<-cov(F_Data)
Inv_Data_Cov <- solve(Data_Cov)
Dif_Med<- Data_means - mu0
T_2<-n%*%t(Dif_Med)%*%Inv_Data_Cov%*%Dif_Med
return(T_2)
}

T2_V <- T2_Hot(mu_value,0.05,25)

alpha=0.05
p=9
n=25
qf<-qf(alpha,p,n-p,lower.tail = F)
Vc<- round((((n-1)*p)/(n-p))*qf,5)

results_df <- data.frame(
  `Valor Estad√≠stico` = T2_V,
  `Valor Cr√≠tico` = Vc
)

kable(results_df)
```
Como el valor estad√≠stico (64.84185) es superior al valor cr√≠tico (34.2585), se rechaza la hip√≥tesis nula \( H_0 \). Esto sugiere que hay suficiente evidencia para concluir que el promedio de gramos de distintos prote√≠na consumidos no coincide con los valores propuestos en \(\mu_0\).


```{r Prueba formal, message=FALSE, warning=FALSE}

# ----- Prueba de Shapiro ----- #
require(mvShapiroTest)
mvShapiro.Test(X)
# ----- Otras Pruebas ----- #
mvn(X, mvnTest="mardia") # test de Mardia
mvn(X, mvnTest="hz") # test de Henze-Zirkler
mvn(X, mvnTest="royston") # test de Royston
mvn(X, mvnTest="dh") # test de Doornik-Hansen
```
